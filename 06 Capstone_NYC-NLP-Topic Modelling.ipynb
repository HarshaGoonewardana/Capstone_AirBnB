{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "# Data Science Immersive - General Assembly \n",
    "## Capstone Project\n",
    "Harsha Goonewardana <br>\n",
    "Today"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Natural Language Processing\n",
    "### This notebook will segregate the top 25% and the bottom 25% in price and conduct unseurvised learning via a latent Dirichlet allocation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "pd.options.display.max_columns = None\n",
    "import seaborn as sns\n",
    "import textacy\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.models.tfidfmodel import TfidfModel\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "\n",
    "import itertools\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "\n",
    "import json\n",
    "import pyLDAvis.gensim\n",
    "pyLDAvis.enable_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_pickle('./data/airbnbNYCclean.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the size of each description field was 7 million words which is too big for textcy/ spacy  to handle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>property_type</th>\n",
       "      <th>room_type</th>\n",
       "      <th>accommodates</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>beds</th>\n",
       "      <th>price</th>\n",
       "      <th>guests_included</th>\n",
       "      <th>extra_people</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>security_deposit</th>\n",
       "      <th>amenities</th>\n",
       "      <th>house_rules</th>\n",
       "      <th>host_since</th>\n",
       "      <th>host_is_superhost</th>\n",
       "      <th>cancellation_policy</th>\n",
       "      <th>neighbourhood_cleansed</th>\n",
       "      <th>reviews_per_month</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>bed_type</th>\n",
       "      <th>ppl_bath</th>\n",
       "      <th>guest_prop</th>\n",
       "      <th>bnb_yield</th>\n",
       "      <th>tier</th>\n",
       "      <th>tier_price</th>\n",
       "      <th>DateDiffHostSince</th>\n",
       "      <th>Location</th>\n",
       "      <th>dist_transit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Step into our artistic spacious apartment and ...</td>\n",
       "      <td>168.0</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Private room</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{TV,\"Cable TV\",Internet,Wifi,\"Air conditioning...</td>\n",
       "      <td>no-smoking/please take off your shoes: cleanin...</td>\n",
       "      <td>2008-09-06</td>\n",
       "      <td>f</td>\n",
       "      <td>strict_14_with_grace_period</td>\n",
       "      <td>Harlem</td>\n",
       "      <td>1.43</td>\n",
       "      <td>40.799205</td>\n",
       "      <td>-73.953676</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>17425.408</td>\n",
       "      <td>2nd</td>\n",
       "      <td>3rd</td>\n",
       "      <td>3601.0</td>\n",
       "      <td>(40.79920479936168, -73.95367574543542)</td>\n",
       "      <td>0.115468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Renovated apt home in elevator building. Spaci...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Private room</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>{TV,\"Cable TV\",Internet,Wifi,\"Air conditioning...</td>\n",
       "      <td>-The security and comfort of all our guests is...</td>\n",
       "      <td>2008-09-07</td>\n",
       "      <td>t</td>\n",
       "      <td>moderate</td>\n",
       "      <td>Kensington</td>\n",
       "      <td>0.23</td>\n",
       "      <td>40.647486</td>\n",
       "      <td>-73.972370</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>2449.408</td>\n",
       "      <td>3rd</td>\n",
       "      <td>3rd</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>(40.64748608166989, -73.97236954007957)</td>\n",
       "      <td>0.392200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Find your romantic getaway to this beautiful, ...</td>\n",
       "      <td>32.0</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>325.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>{TV,Wifi,\"Air conditioning\",Kitchen,\"Paid park...</td>\n",
       "      <td>Make yourself at home, respect the space and t...</td>\n",
       "      <td>2008-09-09</td>\n",
       "      <td>f</td>\n",
       "      <td>strict_14_with_grace_period</td>\n",
       "      <td>Midtown</td>\n",
       "      <td>0.31</td>\n",
       "      <td>40.753621</td>\n",
       "      <td>-73.983774</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10316.800</td>\n",
       "      <td>3rd</td>\n",
       "      <td>1st</td>\n",
       "      <td>3598.0</td>\n",
       "      <td>(40.753620726572464, -73.98377381114605)</td>\n",
       "      <td>0.085077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This is a spacious, clean, furnished master be...</td>\n",
       "      <td>32.0</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Private room</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>{TV,Internet,Wifi,\"Wheelchair accessible\",Kitc...</td>\n",
       "      <td>Guests should be respectful of the home and th...</td>\n",
       "      <td>2008-11-09</td>\n",
       "      <td>f</td>\n",
       "      <td>strict_14_with_grace_period</td>\n",
       "      <td>Williamsburg</td>\n",
       "      <td>0.31</td>\n",
       "      <td>40.708558</td>\n",
       "      <td>-73.942362</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6190.080</td>\n",
       "      <td>3rd</td>\n",
       "      <td>2nd</td>\n",
       "      <td>3537.0</td>\n",
       "      <td>(40.70855778333159, -73.94236227640226)</td>\n",
       "      <td>0.216335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Urban retreat: enjoy 500 s.f. floor in 1899 br...</td>\n",
       "      <td>198.0</td>\n",
       "      <td>Other</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>{TV,\"Cable TV\",Internet,Wifi,\"Air conditioning...</td>\n",
       "      <td>Smoking - outside please; pets allowed but ple...</td>\n",
       "      <td>2008-12-07</td>\n",
       "      <td>f</td>\n",
       "      <td>moderate</td>\n",
       "      <td>Clinton Hill</td>\n",
       "      <td>4.42</td>\n",
       "      <td>40.685138</td>\n",
       "      <td>-73.959757</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>40282.112</td>\n",
       "      <td>2nd</td>\n",
       "      <td>3rd</td>\n",
       "      <td>3509.0</td>\n",
       "      <td>(40.68513770564301, -73.95975749881094)</td>\n",
       "      <td>0.403653</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description  number_of_reviews  \\\n",
       "0  Step into our artistic spacious apartment and ...              168.0   \n",
       "1  Renovated apt home in elevator building. Spaci...                7.0   \n",
       "2  Find your romantic getaway to this beautiful, ...               32.0   \n",
       "3  This is a spacious, clean, furnished master be...               32.0   \n",
       "4  Urban retreat: enjoy 500 s.f. floor in 1899 br...              198.0   \n",
       "\n",
       "  property_type        room_type  accommodates  bathrooms  bedrooms  beds  \\\n",
       "0     Apartment     Private room           3.0        1.0       1.0   2.0   \n",
       "1     Apartment     Private room           4.0        1.0       2.0   3.0   \n",
       "2     Apartment  Entire home/apt           2.0        1.0       0.0   1.0   \n",
       "3     Apartment     Private room           2.0        1.0       1.0   1.0   \n",
       "4         Other  Entire home/apt           3.0        1.0       1.0   3.0   \n",
       "\n",
       "   price  guests_included  extra_people  minimum_nights  security_deposit  \\\n",
       "0  119.0              2.0          39.0             2.0               0.0   \n",
       "1  104.0              1.0          25.0             1.0             100.0   \n",
       "2  325.0              2.0           0.0             1.0             350.0   \n",
       "3  195.0              2.0          50.0             5.0             150.0   \n",
       "4   89.0              1.0           0.0             1.0             500.0   \n",
       "\n",
       "                                           amenities  \\\n",
       "0  {TV,\"Cable TV\",Internet,Wifi,\"Air conditioning...   \n",
       "1  {TV,\"Cable TV\",Internet,Wifi,\"Air conditioning...   \n",
       "2  {TV,Wifi,\"Air conditioning\",Kitchen,\"Paid park...   \n",
       "3  {TV,Internet,Wifi,\"Wheelchair accessible\",Kitc...   \n",
       "4  {TV,\"Cable TV\",Internet,Wifi,\"Air conditioning...   \n",
       "\n",
       "                                         house_rules host_since  \\\n",
       "0  no-smoking/please take off your shoes: cleanin... 2008-09-06   \n",
       "1  -The security and comfort of all our guests is... 2008-09-07   \n",
       "2  Make yourself at home, respect the space and t... 2008-09-09   \n",
       "3  Guests should be respectful of the home and th... 2008-11-09   \n",
       "4  Smoking - outside please; pets allowed but ple... 2008-12-07   \n",
       "\n",
       "  host_is_superhost          cancellation_policy neighbourhood_cleansed  \\\n",
       "0                 f  strict_14_with_grace_period                 Harlem   \n",
       "1                 t                     moderate             Kensington   \n",
       "2                 f  strict_14_with_grace_period                Midtown   \n",
       "3                 f  strict_14_with_grace_period           Williamsburg   \n",
       "4                 f                     moderate           Clinton Hill   \n",
       "\n",
       "   reviews_per_month   latitude  longitude  bed_type  ppl_bath  guest_prop  \\\n",
       "0               1.43  40.799205 -73.953676  Real Bed       0.5    0.666667   \n",
       "1               0.23  40.647486 -73.972370  Real Bed       1.0    0.250000   \n",
       "2               0.31  40.753621 -73.983774  Real Bed       0.5    1.000000   \n",
       "3               0.31  40.708558 -73.942362  Real Bed       0.5    1.000000   \n",
       "4               4.42  40.685138 -73.959757  Real Bed       1.0    0.333333   \n",
       "\n",
       "   bnb_yield tier tier_price  DateDiffHostSince  \\\n",
       "0  17425.408  2nd        3rd             3601.0   \n",
       "1   2449.408  3rd        3rd             3600.0   \n",
       "2  10316.800  3rd        1st             3598.0   \n",
       "3   6190.080  3rd        2nd             3537.0   \n",
       "4  40282.112  2nd        3rd             3509.0   \n",
       "\n",
       "                                   Location  dist_transit  \n",
       "0   (40.79920479936168, -73.95367574543542)      0.115468  \n",
       "1   (40.64748608166989, -73.97236954007957)      0.392200  \n",
       "2  (40.753620726572464, -73.98377381114605)      0.085077  \n",
       "3   (40.70855778333159, -73.94236227640226)      0.216335  \n",
       "4   (40.68513770564301, -73.95975749881094)      0.403653  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[['description','tier']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(txt):\n",
    "    '''\n",
    "    Return cleansed text by tokenizing, stripping stopwords, and lemmatizing the tokens. This function is used prior to performing text analysis and topic modeling.\n",
    "    '''\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(str(txt).lower())\n",
    "\n",
    "    sw = set(stopwords.words('english'))\n",
    "    stopped_tokens = [i for i in tokens if not i in sw]\n",
    "\n",
    "    wordnet = WordNetLemmatizer()\n",
    "    clean_txt = ' '.join([wordnet.lemmatize(i) for i in stopped_tokens])\n",
    "\n",
    "    return clean_txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 25 Percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess the observations for topic modelling\n",
    "X = df[df['tier'] == '1st']['description'].values\n",
    "new_X = []\n",
    "for description in X:\n",
    "    new_X.append(process_text(description))\n",
    "\n",
    "max_features = 1000\n",
    "tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2, max_features=max_features, stop_words='english')\n",
    "\n",
    "tf = tf_vectorizer.fit_transform(new_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/anaconda3/envs/dsi/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n",
      "/Users/admin/anaconda3/envs/dsi/lib/python3.6/site-packages/pyLDAvis/_prepare.py:257: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  return pd.concat([default_term_info] + list(topic_dfs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Note: if you're in the IPython notebook, pyLDAvis.show() is not the best command\n",
      "      to use. Consider using pyLDAvis.display(), or pyLDAvis.enable_notebook().\n",
      "      See more information at http://pyLDAvis.github.io/quickstart.html .\n",
      "\n",
      "You must interrupt the kernel to end this command\n",
      "\n",
      "Serving to http://127.0.0.1:8891/    [Ctrl-C to exit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [17/Jul/2018 10:07:59] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [17/Jul/2018 10:08:00] \"GET /LDAvis.css HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [17/Jul/2018 10:08:00] \"GET /d3.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [17/Jul/2018 10:08:00] \"GET /LDAvis.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [17/Jul/2018 10:08:01] code 404, message Not Found\n",
      "127.0.0.1 - - [17/Jul/2018 10:08:01] \"GET /favicon.ico HTTP/1.1\" 404 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "stopping Server...\n"
     ]
    }
   ],
   "source": [
    "n_topics = 4\n",
    "lda_model = LatentDirichletAllocation(n_topics=n_topics, max_iter=15, learning_method='online', learning_offset=10., n_jobs=-1, random_state=42)\n",
    "\n",
    "lda_model.fit(tf)\n",
    "vis_data = pyLDAvis.sklearn.prepare(lda_model, tf, tf_vectorizer, R=10, n_jobs=-1)\n",
    "# pyLDAvis.display(vis_data)\n",
    "pyLDAvis.show(vis_data)\n",
    "#     pyLDAvis.save_html(vis_data, 'web_app/templates/pylda.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic 4 seems to be "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attrib https://stackoverflow.com/questions/44208501/getting-topic-word-distribution-from-lda-in-scikit-learn\n",
    "vocab = tf_vectorizer.get_feature_names()\n",
    "topic_words = {}\n",
    "n_top_words = 10\n",
    "for topic, comp in enumerate(lda_model.components_):\n",
    "    # for the n-dimensional array \"arr\":\n",
    "    # argsort() returns a ranked n-dimensional array of arr, call it \"ranked_array\"\n",
    "    # which contains the indices that would sort arr in a descending fashion\n",
    "    # for the ith element in ranked_array, ranked_array[i] represents the index of the\n",
    "    # element in arr that should be at the ith index in ranked_array\n",
    "    # ex. arr = [3,7,1,0,3,6]\n",
    "    # np.argsort(arr) -> [3, 2, 0, 4, 5, 1]\n",
    "    # word_idx contains the indices in \"topic\" of the top num_top_words most relevant\n",
    "    # to a given topic ... it is sorted ascending to begin with and then reversed (desc. now)    \n",
    "    word_idx = np.argsort(comp)[::-1][:n_top_words]\n",
    "\n",
    "    # store the words most relevant to the topic\n",
    "    topic_words[topic] = [vocab[i] for i in word_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0\n",
      "  bedroom, apartment, room, floor, bed, private, living, kitchen, bathroom, space\n",
      "Topic: 1\n",
      "  apartment, new, city, york, east, nyc, village, located, space, bedroom\n",
      "Topic: 2\n",
      "  bed, apartment, bedroom, kitchen, room, queen, tv, size, new, living\n",
      "Topic: 3\n",
      "  apartment, minute, block, park, subway, walk, away, restaurant, train, time\n"
     ]
    }
   ],
   "source": [
    "for topic, words in topic_words.items():\n",
    "    print('Topic: %d' % topic)\n",
    "    print('  %s' % ', '.join(words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bottom 25 percent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = df[df['tier_price'] == '4th']['description'].values\n",
    "new_X = []\n",
    "for description in X:\n",
    "    new_X.append(process_text(description))\n",
    "\n",
    "max_features = 1000\n",
    "tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2, max_features=max_features, stop_words='english')\n",
    "\n",
    "tf = tf_vectorizer.fit_transform(new_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_topics = 4\n",
    "lda_model = LatentDirichletAllocation(n_topics=n_topics, max_iter=15, learning_method='online', learning_offset=10., n_jobs=-1, random_state=42)\n",
    "\n",
    "lda_model.fit(tf)\n",
    "vis_data = pyLDAvis.sklearn.prepare(lda_model, tf, tf_vectorizer, R=10, n_jobs=-1)\n",
    "pyLDAvis.display(vis_data)\n",
    "#     pyLDAvis.show(vis_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#attribution https://github.com/Stuart-D-King/the_hub\n",
    "vocab = tf_vectorizer.get_feature_names()\n",
    "topic_words = {}\n",
    "n_top_words = 10\n",
    "for topic, comp in enumerate(lda_model.components_):\n",
    "    # for the n-dimensional array \"arr\":\n",
    "    # argsort() returns a ranked n-dimensional array of arr, call it \"ranked_array\"\n",
    "    # which contains the indices that would sort arr in a descending fashion\n",
    "    # for the ith element in ranked_array, ranked_array[i] represents the index of the\n",
    "    # element in arr that should be at the ith index in ranked_array\n",
    "    # ex. arr = [3,7,1,0,3,6]\n",
    "    # np.argsort(arr) -> [3, 2, 0, 4, 5, 1]\n",
    "    # word_idx contains the indices in \"topic\" of the top num_top_words most relevant\n",
    "    # to a given topic ... it is sorted ascending to begin with and then reversed (desc. now)    \n",
    "    word_idx = np.argsort(comp)[::-1][:n_top_words]\n",
    "\n",
    "    # store the words most relevant to the topic\n",
    "    topic_words[topic] = [vocab[i] for i in word_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for topic, words in topic_words.items():\n",
    "    print('Topic: %d' % topic)\n",
    "    print('  %s' % ', '.join(words))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hosts clusters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
